#
# the pipeline to pass parameters to a model and
# eventually expose the deployment port to the outside. 
#
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: inferencing-demo-
spec:
  entrypoint: inferencing-example
  templates:
  - name: inferencing-example
    steps:
    - - name: generate-input
        template: whalesay
    - - name: consume-input
        template: run-model
        arguments:
          artifacts:
          # bind message to the intput-art artifact
          # generated by the generate-input step
          - name: message
            from: "{{steps.generate-input.outputs.artifacts.input-art}}"

  - name: whalesay
    container:
      #image: docker/whalesay:latest
      image: alpine:latest
      command: [sh, -c]
      args: ["echo -e \"{\\\"x\\\":3.0}\" | tee /tmp/message"]
    outputs:
      artifacts:
      # generate hello-art artifact from /tmp/message
      # artifacts can be directories as well as files
      - name: input-art
        path: /tmp/message

  - name: run-model
    inputs:
      artifacts:
      # unpack the message input artifact
      # and put it at /tmp/message
      - name: message
        path: /tmp/message
    container:
      image: alpine:latest
      command: [sh, -c]
      args: ["cat /tmp/message"]
